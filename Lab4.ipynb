{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 4793070,
          "sourceType": "datasetVersion",
          "datasetId": 2774887
        },
        {
          "sourceId": 8589885,
          "sourceType": "datasetVersion",
          "datasetId": 5137926
        },
        {
          "sourceId": 8589967,
          "sourceType": "datasetVersion",
          "datasetId": 5137967
        }
      ],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "LAB 4",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyansh295/Lab-Portal/blob/main/Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'car-damage-severity-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2774887%2F4793070%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240607%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240607T082719Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D999877f0fc4f371aa49364c89c205c77aa2fe1e403ed23ecbb0c83501a1c3805af1825dcac7373c644e7ab998fddf9fe4287552292f29c5d9829e8867e6b3cc78b584425c13e8d5e846ed0eaeaf9e5264e5fb27a9cb8e63fb910172f88b2a3523b3b549fd20ae6c4bfcf4ac4e8f721bd63b93910ec04a9bfe6476033167f4a31652b72b4e5727e7ccdb34fccd61163aa630fc633c1ba497f2f9a274914dcce9ef6c4bdaebd9cdf0e27fa4ff672e7f22a97033cb77ac50909aac83240255535cf5168fb1f872fb9ea390852a419c24114b0ada15916c8e0e113714677b44d86c08d3c664d5b7e747d9ac5bc441ed3e6f602ba05c4eab173ee39bacfafae955f7f'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "06X9b2l9z1VC"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras import regularizers\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-07T05:32:54.904151Z",
          "iopub.execute_input": "2024-06-07T05:32:54.904467Z",
          "iopub.status.idle": "2024-06-07T05:33:07.346746Z",
          "shell.execute_reply.started": "2024-06-07T05:32:54.904441Z",
          "shell.execute_reply": "2024-06-07T05:33:07.345773Z"
        },
        "trusted": true,
        "id": "UazL9-jwz1VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "CoacBY36z1VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_path = '/kaggle/input/car-damage-severity-dataset/data3a/training'\n",
        "test_img_path = '/kaggle/input/car-damage-severity-dataset/data3a/validation'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.348643Z",
          "iopub.execute_input": "2024-06-07T05:33:07.349617Z",
          "iopub.status.idle": "2024-06-07T05:33:07.355697Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.349577Z",
          "shell.execute_reply": "2024-06-07T05:33:07.353234Z"
        },
        "trusted": true,
        "id": "A9y08bsXz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.35722Z",
          "iopub.execute_input": "2024-06-07T05:33:07.357606Z",
          "iopub.status.idle": "2024-06-07T05:33:07.389358Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.357569Z",
          "shell.execute_reply": "2024-06-07T05:33:07.388417Z"
        },
        "trusted": true,
        "id": "D_blzwNYz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = ImageDataGenerator(rescale=1 / 255.0,\n",
        "        rotation_range=20,\n",
        "        zoom_range=0.05,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        shear_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.20,)\n",
        "\n",
        "# Use flow_from_directory for the training dataset\n",
        "train_ds = train_data_gen.flow_from_directory(\n",
        "    train_img_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ")\n",
        "valid_ds = train_data_gen.flow_from_directory(\n",
        "    train_img_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.3919Z",
          "iopub.execute_input": "2024-06-07T05:33:07.392281Z",
          "iopub.status.idle": "2024-06-07T05:33:07.588286Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.39225Z",
          "shell.execute_reply": "2024-06-07T05:33:07.58731Z"
        },
        "trusted": true,
        "id": "ymStQouzz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_gen = ImageDataGenerator(rescale=1./255,)  # You may adjust other parameters as needed\n",
        "\n",
        "# Use flow_from_directory for the test dataset\n",
        "test_ds = test_data_gen.flow_from_directory(\n",
        "    test_img_path,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',  # Assuming label_mode='int' in your original code\n",
        "    shuffle=False  # Set to True if you want to shuffle the data\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.589553Z",
          "iopub.execute_input": "2024-06-07T05:33:07.589897Z",
          "iopub.status.idle": "2024-06-07T05:33:07.632811Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.589868Z",
          "shell.execute_reply": "2024-06-07T05:33:07.631998Z"
        },
        "trusted": true,
        "id": "ip1lG3UTz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl=test_ds.class_indices\n",
        "print(cl)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.634078Z",
          "iopub.execute_input": "2024-06-07T05:33:07.634524Z",
          "iopub.status.idle": "2024-06-07T05:33:07.639713Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.634491Z",
          "shell.execute_reply": "2024-06-07T05:33:07.638683Z"
        },
        "trusted": true,
        "id": "pZv5Snnbz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images_from_dataset(dataset, num_images=9):\n",
        "    # Fetch a batch of images and labels from the dataset\n",
        "    images, labels = next(iter(dataset))\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    for i in range(min(num_images, len(images))):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "\n",
        "        # Map the label index back to the original class name\n",
        "        label_index = labels[i].argmax()  # Assumes one-hot encoding\n",
        "        class_name = next(key for key, value in cl.items() if value == label_index)\n",
        "\n",
        "        plt.title(f\"Class: {class_name}\")\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Assuming test_ds is your dataset\n",
        "plot_images_from_dataset(test_ds)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:07.641095Z",
          "iopub.execute_input": "2024-06-07T05:33:07.641423Z",
          "iopub.status.idle": "2024-06-07T05:33:08.909797Z",
          "shell.execute_reply.started": "2024-06-07T05:33:07.641391Z",
          "shell.execute_reply": "2024-06-07T05:33:08.908839Z"
        },
        "trusted": true,
        "id": "xJvVmkqfz1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **CNN USING PRETRAINED EFF NET****\n",
        "****"
      ],
      "metadata": {
        "id": "uO3LCv94z1VF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Convolutional Neural Network (CNN) is a type of artificial intelligence model specifically designed for analyzing visual data, such as images. It works by using layers of filters (also called kernels) that automatically learn to detect important features in the images, like edges, textures, and shapes. These filters slide over the image and create feature maps that highlight these detected features, allowing the network to understand and identify various patterns within the image.\n",
        "\n",
        "CNNs are particularly effective for image-related tasks because they can recognize spatial hierarchies in data. This means they can first identify simple features (like edges) and then combine them to recognize more complex structures (like shapes and objects). As a result, CNNs are widely used for image classification, object detection, and other tasks where understanding visual content is crucial. They help computers achieve tasks like recognizing faces in photos, detecting objects in videos, or even driving cars by interpreting camera inputs.\n",
        "![image.png](attachment:2488b779-4068-4bff-9b00-7f093dcb4ea0.png)"
      ],
      "metadata": {
        "id": "MpHQ_Eazz1VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "img_size = (224, 224)\n",
        "lr = 0.001\n",
        "class_count = 3\n",
        "\n",
        "img_shape = (img_size[0], img_size[1], 3)\n",
        "\n",
        "base_model = DenseNet169(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
        "base_model.trainable = True\n",
        "x = base_model.output\n",
        "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(x)\n",
        "x = Dense(256, kernel_regularizer=regularizers.l2(l=0.016),\n",
        "          activity_regularizer=regularizers.l1(0.006),\n",
        "          bias_regularizer=regularizers.l1(0.006), activation='relu')(x)\n",
        "x = Dropout(rate=.4, seed=123)(x)\n",
        "output = Dense(class_count, activation='softmax')(x)\n",
        "model_eff = Model(inputs=base_model.input, outputs=output)\n",
        "model_eff.compile(Adamax(learning_rate=lr), loss='categorical_crossentropy',\n",
        "              metrics=['accuracy','AUC'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:08.911042Z",
          "iopub.execute_input": "2024-06-07T05:33:08.911365Z",
          "iopub.status.idle": "2024-06-07T05:33:15.231421Z",
          "shell.execute_reply.started": "2024-06-07T05:33:08.911339Z",
          "shell.execute_reply": "2024-06-07T05:33:15.230631Z"
        },
        "trusted": true,
        "id": "OisGTG65z1VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses a pre-trained DenseNet169 model, which means it’s a model that has already been trained on a large dataset (ImageNet) and knows how to recognize many common features in images. We exclude the final layers of DenseNet169 to add our own custom layers for our specific task. This allows us to take advantage of the pre-trained model's knowledge and adapt it to classify images into three categories.\n",
        "\n",
        "The added layers include batch normalization to stabilize and speed up training, a dense layer with regularization to prevent overfitting, dropout to randomly turn off some neurons during training for better generalization, and a final dense layer with softmax activation to output probabilities for each class. Using this pre-trained model helps our new model learn faster and perform better with less training data and time. This approach is known as transfer learning.\n",
        "![![image.png](attachment:a300db1f-0fdb-4b70-a291-2ce20f11363f.png)]\n"
      ],
      "metadata": {
        "id": "CKDkx9X2z1VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "\n",
        "# Train the model\n",
        "history_eff = model_eff.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=valid_ds,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Save training and validation histories for later analysis\n",
        "all_train_histories = [history_eff.history['accuracy']]\n",
        "all_val_histories = [history_eff.history['val_accuracy']]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-07T05:33:15.232677Z",
          "iopub.execute_input": "2024-06-07T05:33:15.233043Z"
        },
        "trusted": true,
        "id": "0UcIA4Wjz1VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_eff.save('model_eff.h5')"
      ],
      "metadata": {
        "trusted": true,
        "id": "A6VThSrqz1VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we train a neural network model, we do it in cycles called epochs. Each epoch represents one complete pass through the entire training dataset. During each epoch, the model makes predictions on the training data, calculates errors (differences between predicted and actual values), and adjusts its internal parameters (weights) to reduce these errors. This process of predicting, calculating errors, and updating weights is repeated for a specified number of epochs or until the model's performance stops improving.\n",
        "\n",
        "Saving weights during training means storing the current values of the model’s parameters. These weights are essentially the learned features that the model has identified as important for making accurate predictions. By saving these weights, we can preserve the state of the model at a particular point in training. This is useful for several reasons: it allows us to resume training later if needed, to prevent losing progress if the training process is interrupted, and to use the trained model for making predictions on new data without retraining it from scratch. Additionally, saving the best weights (those that achieve the highest accuracy on validation data) ensures we have the most effective version of the model for deployment"
      ],
      "metadata": {
        "id": "MLL1Wsa3z1VF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to predict and display the image with its predicted class\n",
        "def predict_and_display_image(image_path, model):\n",
        "    # Preprocess the image\n",
        "    processed_image = preprocess_image(image_path)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(processed_image)\n",
        "\n",
        "    # Get the predicted class label\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    class_name = next(key for key, value in cl.items() if value == predicted_class_index)\n",
        "\n",
        "    # Display the image with its predicted class\n",
        "    img = load_img(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Class: {class_name}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Path to your own image\n",
        "your_image_path = '/kaggle/input/test-2-minor/0015.JPEG'  # Change this to your image path\n",
        "\n",
        "# Predict and display the image\n",
        "predict_and_display_image(your_image_path, model_eff)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "WVUEev72z1VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "9N8y9X5Dz1VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Try uploading pictures of damaged vehicles and see whether those damages are minor, major or severe**\n"
      ],
      "metadata": {
        "id": "tuENBSwQz1VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to preprocess image\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array\n",
        "\n",
        "# Function to predict and display the image with its predicted class\n",
        "def predict_and_display_image(image_path, model):\n",
        "    # Preprocess the image\n",
        "    processed_image = preprocess_image(image_path)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(processed_image)\n",
        "\n",
        "    # Get the predicted class label\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    class_name = next(key for key, value in cl.items() if value == predicted_class_index)\n",
        "\n",
        "    # Display the image with its predicted class\n",
        "    img = load_img(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Class: {class_name}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Define the upload button and output widget\n",
        "upload_btn = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle the image upload and classification\n",
        "def on_upload_change(change):\n",
        "    for filename, file_info in change['new'].items():\n",
        "        # Save the uploaded image to a temporary path\n",
        "        with open('uploaded_image.jpg', 'wb') as f:\n",
        "            f.write(file_info['content'])\n",
        "\n",
        "        # Display the image and prediction\n",
        "        with output:\n",
        "            output.clear_output()  # Clear previous outputs\n",
        "            predict_and_display_image('uploaded_image.jpg', model_eff)\n",
        "\n",
        "# Attach the function to the upload button\n",
        "upload_btn.observe(on_upload_change, names='value')\n",
        "\n",
        "# Display the upload button and output widget\n",
        "display(upload_btn, output)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "bg0GZWfqz1VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = img_array / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array\n",
        "\n",
        "def predict_and_display_image(image_path, model):\n",
        "    processed_image = preprocess_image(image_path)\n",
        "    predictions = model.predict(processed_image)\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    class_name = next(key for key, value in cl.items() if value == predicted_class_index)\n",
        "    img = load_img(image_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted Class: {class_name}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "upload_btn = widgets.FileUpload(accept='image/*', multiple=False)\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_upload_change(change):\n",
        "    for filename, file_info in change['new'].items():\n",
        "        with open('uploaded_image.jpg', 'wb') as f:\n",
        "            f.write(file_info['content'])\n",
        "        with output:\n",
        "            output.clear_output()\n",
        "            predict_and_display_image('uploaded_image.jpg', model_eff)\n",
        "\n",
        "upload_btn.observe(on_upload_change, names='value')\n",
        "display(upload_btn, output)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "wLUNumnYz1VG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}